{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to OpenCV.ipynb","provenance":[{"file_id":"1DqZeWEiAoKirFwvVuSEdNgQ2SWYtUKNo","timestamp":1642439791261}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VTTLqcIYkJss"},"source":["#OpenCV Workshop - Introduction"]},{"cell_type":"markdown","metadata":{"id":"dJzyP9VQlb0-"},"source":["Lesson 1\n","#Intro: Loading Images & Video Sources"]},{"cell_type":"code","metadata":{"id":"tqjb3PJfnVpv"},"source":["#Lesson 1.1: loading image sources\n","\n","import cv2\n","\n","#openCV operates in BGR and not RGB\n","\n","img = cv2.imread('messi.jpeg',cv2.IMREAD_UNCHANGED)\n","#IMREAD_GRAYSCALE = 0\n","#IMREAD_COLOR = 1\n","#IMREAD_UNCHANGED = -1\n","img = cv2.resize(img,(512,512))\n","\n","cv2.imshow('image',img)\n","#to close window manually\n","cv2.waitKey(0)\n","#to wait for 5 seconds before closing the window\n","#cv2.waitKey(5000)\n","cv2.destroyAllWindows()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Lesson 1.2: different methods of closing image and other functions\n","\n","import cv2\n","\n","#openCV operates in BGR and not RGB\n","\n","img = cv2.imread('messi.jpeg',cv2.IMREAD_UNCHANGED)\n","\n","#to print the DDA of pixels of image\n","#print(img)\n","\n","img = cv2.resize(img,(512,512))\n","\n","cv2.imshow('image',img)\n","k = cv2.waitKey(0) & 0xFF\n","\n","if k == 27:  #27 is the Esc key\n","    cv2.destroyAllWindows()  \n","elif k == ord('s'):  #pressing the 's' key\n","    cv2.imwrite('messi_copy.png',img) #creates a copy of the image\n","    cv2.destroyAllWindows()\n"],"metadata":{"id":"CAn3bz7exuN4"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aRdqgsEnv7L"},"source":["#Lesson 1.3: loading video source\n","\n","import cv2\n","\n","cap = cv2.VideoCapture(0) #argument is video-cam index of your system\n","\n","#for saving video as a file\n","#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","#out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n","\n","while(True): #or use cap.isOpened()\n","    ret, frame = cap.read()\n","    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    cv2.imshow('frame',frame)\n","    #cv2.imshow('gray',gray)\n","    #out.write(frame)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","#out.release()\n","cv2.destroyAllWindows()\n","\n","#find all other properties here: https://docs.opencv.org/4.0.0/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGo5K4dsojsr"},"source":["Lesson 2\n","#Drawing & Writing on Images"]},{"cell_type":"code","metadata":{"id":"A83i8k2roydc"},"source":["import numpy as np\n","import cv2\n","\n","#img = cv2.imread('messi.jpeg', 1)\n","img = np.zeros([512, 512, 3], np.uint8)\n","\n","#Creates a line on the image\n","img = cv2.line(img, (0,0), (255,255), (147, 96, 44), 10) # 44, 96, 147\n","img = cv2.arrowedLine(img, (0,255), (255,255), (255, 0, 0), 10)\n","\n","#Creates a rectangle on the image\n","img = cv2.rectangle(img, (384, 0), (510, 128), (0, 0, 255), 10)\n","\n","#Creates a circle on the image\n","img = cv2.circle(img, (447, 63), 63, (0, 255, 0), -1)\n","\n","#Writes on the image\n","font = cv2.FONT_HERSHEY_SIMPLEX\n","img = cv2.putText(img, 'OpenCv', (10, 500), font, 4, (0, 255, 255), 10, cv2.LINE_AA)\n","\n","#Creates an ellipse on the image\n","img = cv2.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n","\n","#Creates a line on the image\n","pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n","pts = pts.reshape((-1,1,2))\n","img = cv2.polylines(img,[pts],True,(0,255,255))\n","cv2.imshow('image', img)\n","\n","cv2.waitKey(0)\n","cv2.destroyAllWindows() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDRGFaRYpLML"},"source":["Lesson 3\n","#Image Operations"]},{"cell_type":"code","source":["#lesson 3.1: finding image properties\n","\n","import cv2\n","import numpy as np\n","\n","# Print Pixel values\n","img = cv2.imread('messi.jpeg')\n","pixel = img[100,100]\n","print(pixel)\n","\n","# See Image Properties\n","height = img.shape[0]\n","width = img.shape[1]\n","channels = img.shape[2]\n","size1 = img.size\n","\n","print('Image Height       : ', height)\n","print('Image Width        : ', width)\n","print('Number of Channels : ', channels)\n","print('Image Size  :', size1)\n"],"metadata":{"id":"4x_YNDKtOVE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lesson 3.2: few image operations\n","\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","BLUE = [255,0,0]\n","\n","img1 = cv2.imread('messi.jpg')\n","img1 = cv2.resize(img1, (512,512))\n","\n","replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)\n","reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)\n","reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)\n","wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)\n","constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)\n","\n","plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n","plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n","plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n","plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n","plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n","plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n","\n","plt.show()\n"],"metadata":{"id":"RS9qU07uOYvV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ri6spofpqe_c"},"source":["Lesson 4\n","#Image Arithmetic"]},{"cell_type":"code","metadata":{"id":"LHHEHfNFrX5C"},"source":["#lesson 4: bitwise arithmetic opetations on images\n","\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","img1 = np.zeros((250, 500, 3), np.uint8)\n","img1 = cv2.rectangle(img1,(200, 0), (300, 100), (255, 255, 255), -1)\n","img2 = cv2.imread(\"image_1.jpeg\")\n","\n","bitAnd = cv2.bitwise_and(img2, img1)\n","bitOr = cv2.bitwise_or(img2, img1)\n","bitXor = cv2.bitwise_xor(img1, img2)\n","bitNot1 = cv2.bitwise_not(img1)\n","bitNot2 = cv2.bitwise_not(img2)\n","\n","'''\n","cv2.imshow(\"img1\", img1)\n","cv2.imshow(\"img2\", img2)\n","cv2.imshow('bitAnd', bitAnd)\n","cv2.imshow('bitOr', bitOr)\n","cv2.imshow('bitXor', bitXor)\n","cv2.imshow('bitNot1', bitNot1)\n","cv2.imshow('bitNot2', bitNot2)\n","\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","'''\n","\n","titles = ['img1','img2','bitAnd','bitOr','bitXor','bitNot1','bitNot2']\n","images = [img1,img2,bitAnd,bitOr,bitXor,bitNot1,bitNot2]\n","\n","for i in range (7):\n","    plt.subplot(3,3,i+1), plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bMgWUceErpWM"},"source":["Lesson 5\n","#Thresholding"]},{"cell_type":"code","metadata":{"id":"QM3rbYelru5T"},"source":["#lesson 5.1: basic thresholding\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","img = cv2.imread('gradient.jpeg',0)\n","_, th1 = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY)\n","_, th2 = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY_INV)\n","_, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)\n","_, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)\n","_, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n","\n","titles = ['image','binary','inv binary','truncated','to zero','inv to zero']\n","images = [img,th1,th2,th3,th4,th5]\n","\n","for i in range (6):\n","    plt.subplot(2,3,i+1), plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZRHww_oMPCH"},"source":["#lesson 5.2: adaptive thresholding\n","\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","\n","img = cv.imread('book.jpeg',0)\n","_, th1 = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n","th2 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 11, 2);\n","th3 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);\n","\n","titles = ['image','binary','mean','gaussian']\n","images = [img,th1,th2,th3]\n","\n","for i in range (4):\n","    plt.subplot(2,2,i+1), plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()\n","\n","#check the documentation for detailed explanation: https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gM5PESI3PaYh"},"source":["Lesson 6\n","#Color Filtering"]},{"cell_type":"code","metadata":{"id":"i6xyF-wfPjDI"},"source":["#lesson 6.1: color filtering\n","\n","import cv2\n","import numpy as np\n","\n","img = cv2.imread(\"messi.jpeg\")\n","\n","# Convert the BGR image to HSV colour space\n","hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","\n","# set the lower and upper bounds for the green hue\n","lower_green = np.array([50,100,50])\n","upper_green = np.array([70,255,255])\n","\n","# Create a mask for green colour using inRange function\n","msk = cv2.inRange(hsv, lower_green, upper_green)\n","\n","# performing bitwise-and on the original image arrays using the mask\n","res = cv2.bitwise_and(img, img, mask=msk)\n","\n","# creating resizable windows for displaying the images\n","cv2.namedWindow(\"res\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"hsv\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"mask\", cv2.WINDOW_NORMAL)\n","\n","cv2.imshow(\"mask\", msk)\n","cv2.imshow(\"hsv\", hsv)\n","cv2.imshow(\"res\", res)\n","\n","if cv2.waitKey(0) & 0xFF == ord('q'):\n","    cv2.destroyAllWindows()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lesson 6.2: color filtering in video mode\n","\n","import cv2\n","import numpy as np\n","\n","cap = cv2.VideoCapture(0)\n","\n","while(1):\n","    _, frame = cap.read()\n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    \n","    lower_green = np.array([50,80,50])\n","    upper_green = np.array([100,255,255])\n","\n","    mask = cv2.inRange(hsv, lower_green, upper_green)\n","    res = cv2.bitwise_and(frame,frame, mask=mask)\n","\n","    cv2.imshow('frame',frame)\n","    cv2.imshow('mask',mask)\n","    cv2.imshow('res',res)\n","    \n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","      break\n","\n","cv2.destroyAllWindows()\n","cap.release()\n","\n","'''try finding the range of values for filtering out blue'''\n","'''there's also a way to get the exact values of a color in HSV from BGR, \n","    but that will be for just one color,\n","    code snippet below is for dark red)'''\n","\n","    #dark_red  = np.uint8([[[12,22,121]]])\n","    #dark_red = cv2.cvtColor(dark_red,cv2.COLOR_BGR2HSV)\n"],"metadata":{"id":"WhkqBInLvzhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lesson 6.3: creating color pop effects using color filtering (try it later if you want)\n","\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","img = cv2.imread('messi.jpg')\n","hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","#set the bounds for the red hue\n","lower_red = np.array([160,100,50])\n","upper_red = np.array([180,255,255])\n","\n","#create a mask using the bounds set\n","mask = cv2.inRange(hsv, lower_red, upper_red)\n","#create an inverse of the mask\n","mask_inv = cv2.bitwise_not(mask)\n","#Filter only the red colour from the original image using the mask(foreground)\n","res = cv2.bitwise_and(img, img, mask=mask)\n","#Filter the regions containing colours other than red from the grayscale image(background)\n","background = cv2.bitwise_and(gray, gray, mask = mask_inv)\n","#convert the one channelled grayscale background to a three channelled image\n","background = np.stack((background,)*3, axis=-1)\n","#add the foreground and the background\n","added_img = cv2.add(res, background)\n","\n","\n","#display the images\n","\n","titles = ['gray','hsv','mask','inv mask','res','background','added img']\n","images = [gray,hsv,mask,mask_inv,res,background,added_img]\n","\n","for i in range (7):\n","    plt.subplot(3,3,i+1), plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()\n","\n","'''\n","#create resizable windows for the images\n","cv2.namedWindow(\"res\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"hsv\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"mask\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"added\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"back\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"mask_inv\", cv2.WINDOW_NORMAL)\n","cv2.namedWindow(\"gray\", cv2.WINDOW_NORMAL)\n","\n","cv2.imshow(\"back\", background)\n","cv2.imshow(\"mask_inv\", mask_inv)\n","cv2.imshow(\"added\",added_img)\n","cv2.imshow(\"mask\", mask)\n","cv2.imshow(\"gray\", gray)\n","cv2.imshow(\"hsv\", hsv)\n","cv2.imshow(\"res\", res)\n","\n","if cv2.waitKey(0) & 0xFF == ord('q'):\n","    cv2.destroyAllWindows()\n","'''"],"metadata":{"id":"eKmykNZY6bGs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GZq3MbT069HR"},"source":["Lesson 7\n","#Blurring & Smoothing"]},{"cell_type":"code","metadata":{"id":"RjPtg8EX81fT"},"source":["#lesson 7.1: blurring and smoothing\n","\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","img = cv2.imread('eye.jpg')\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","kernel = np.ones((15, 15), np.float32)/225\n","dst = cv2.filter2D(img, -1, kernel)\n","blur = cv2.blur(img, (15, 15))\n","gblur = cv2.GaussianBlur(img, (15, 15), 0)\n","median = cv2.medianBlur(img, 15)\n","bilateralFilter = cv2.bilateralFilter(img, 15, 75, 75)\n","\n","titles = ['image', '2D Convolution', 'blur', 'Gaussian Blur', 'median', 'Bilateral Filter']\n","images = [img, dst, blur, gblur, median, bilateralFilter]\n","\n","for i in range(6):\n","    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lesson 7.2: blurring and smoothing in video\n","\n","import cv2\n","import numpy as np\n","\n","cap = cv2.VideoCapture(0)\n","\n","while(1):\n","    _, frame = cap.read()\n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    \n","    #lower_green = np.array([50,80,50])\n","    #upper_green = np.array([100,255,255])\n","    \n","    lower_red = np.array([30,150,50])\n","    upper_red = np.array([255,255,180])\n","\n","    #mask = cv2.inRange(hsv, lower_green, upper_green)\n","    mask = cv2.inRange(hsv, lower_red, upper_red)\n","    res = cv2.bitwise_and(frame,frame, mask= mask)\n","\n","    kernel = np.ones((15,15),np.float32)/225\n","    smoothed = cv2.filter2D(res,-1,kernel)\n","    cv2.imshow('Original',frame)\n","    cv2.imshow('Averaging',smoothed)\n","\n","    blur = cv2.GaussianBlur(res,(15,15),0)\n","    cv2.imshow('Gaussian Blurring',blur)\n","\n","    median = cv2.medianBlur(res,15)\n","    cv2.imshow('Median Blur',median)\n","\n","    bilateral = cv2.bilateralFilter(res,15,75,75)\n","    cv2.imshow('Bilateral Blur',bilateral)\n","    \n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","      break\n","\n","cv2.destroyAllWindows()\n","cap.release()\n","\n","#if you want to learn more about how each function works heres some stuff that might help you out\n","#https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html"],"metadata":{"id":"L-r_lq33E_Mo"},"execution_count":null,"outputs":[]}]}