{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intermediate OpenCV.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **OpenCV Workshop Part 2**\n","# **(Intermediate OpenCV)**"],"metadata":{"id":"UAb9_UHHNJTm"}},{"cell_type":"markdown","source":["## **6) Blurring and Smoothing**\n","\n","\n"],"metadata":{"id":"nptqQsdfN96K"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","#Capturing video frames from webcam\n","cap = cv2.VideoCapture(0)\n","while True:\n","    _, frame = cap.read()\n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    lower_red = np.array([150, 100, 0])\n","    upper_red = np.array([180, 225, 255])\n","\n","    #Create Mask\n","    mask = cv2.inRange(hsv, lower_red, upper_red)\n","    res = cv2.bitwise_and(frame, frame, mask=mask)\n","\n","    #Create Kernels\n","    kernel1 = np.ones((15, 15), np.float32) / 225\n","    smoothed1 = cv2.filter2D(res, -1, kernel1)\n","\n","    kernel2 = np.ones((5, 5), np.float32) / 25\n","    smoothed2 = cv2.filter2D(res, -1, kernel2)\n","\n","    cv2.imshow('frame', frame)\n","    cv2.imshow('mask', mask)\n","    cv2.imshow('smooth1', smoothed1)\n","    cv2.imshow('smooth2', smoothed2)\n","\n","    #Different Types of Blur and Smoothing process\n","    blur = cv2.GaussianBlur(res, (15, 15), 0)\n","    median = cv2.medianBlur(res, 15)\n","    bilateral = cv2.bilateralFilter(res, 15, 75, 75)\n","    cv2.imshow('bi', bilateral)\n","    cv2.imshow('blur', blur)\n","    cv2.imshow('median', median)\n","\n","    if cv2.waitKey(1) & 0xff == ord('q'):\n","        break\n","\n","cv2.destroyAllWindows()\n","cap.release()\n"],"metadata":{"id":"-sQmR_lmOuBs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **7) Morphological transformations**"],"metadata":{"id":"XVU5MLDBPHTu"}},{"cell_type":"markdown","source":["## i. **Erosion** and **Dilation**"],"metadata":{"id":"lrxrbk7HPb-C"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","#Capturing video frames from webcam\n","cap = cv2.VideoCapture(0)\n","while True:\n","    _, frame = cap.read()\n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    lower_red = np.array([150, 100, 0])\n","    upper_red = np.array([180, 225, 255])\n","\n","    #Create Mask\n","    mask = cv2.inRange(hsv, lower_red, upper_red)\n","    res = cv2.bitwise_and(frame, frame, mask=mask)\n","\n","    #Erosion and Dilation\n","    kernel = np.ones((5, 5), np.uint8)\n","    erosion = cv2.erode(mask, kernel, iterations=1)\n","    dilation = cv2.dilate(mask, kernel, iterations=1)\n","\n","    cv2.imshow('frame', frame)\n","    cv2.imshow('res', res)\n","    cv2.imshow('erosion', erosion)\n","    cv2.imshow('dilation', dilation)\n","\n","    if cv2.waitKey(1) & 0xff == ord('q'):\n","        break\n","\n","cv2.destroyAllWindows()\n","cap.release()"],"metadata":{"id":"-yX83nxjPTUZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ii. **Opening** and **Closing**"],"metadata":{"id":"a0G-sW5hP9xD"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","#Capturing video frames from webcam\n","cap = cv2.VideoCapture(0)\n","while True:\n","    _, frame = cap.read()\n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    lower_red = np.array([150, 100, 0])\n","    upper_red = np.array([180, 225, 255])\n","\n","    #Create Mask\n","    mask = cv2.inRange(hsv, lower_red, upper_red)\n","    res = cv2.bitwise_and(frame, frame, mask=mask)\n","\n","    #Erosion and Dilation\n","    kernel = np.ones((3, 3), np.uint8)\n","    erosion = cv2.erode(mask, kernel, iterations=1)\n","    dilation = cv2.dilate(mask, kernel, iterations=1)\n","\n","    #Opening and Closing\n","    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n","    closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n","\n","    cv2.imshow('frame', frame)\n","    cv2.imshow('res', res)\n","    cv2.imshow('erosion', erosion)\n","    cv2.imshow('dilation', dilation)\n","    cv2.imshow('opening', opening)\n","    cv2.imshow('closing', closing)\n","\n","    if cv2.waitKey(1) & 0xff == ord('q'):\n","        break\n","\n","cv2.destroyAllWindows()\n","cap.release()\n"],"metadata":{"id":"Eaa2qY6DQOIA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **9) Edge Detection**"],"metadata":{"id":"5f5kxCZYQYmg"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","#Capturing video frames from webcam\n","cap = cv2.VideoCapture(0)\n","while True:\n","    _, frame = cap.read()\n","\n","    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    #Sobel and Canny Edge detectors\n","    sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=5)\n","    sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=5)\n","    sobelxy = cv2.Sobel(img_gray, cv2.CV_64F, 1, 1, ksize=5)\n","    canny = cv2.Canny(img_gray, 50, 50)\n","\n","    cv2.imshow('og', frame)\n","    cv2.imshow('sobelx', sobelx)\n","    cv2.imshow('sobely', sobely)\n","    cv2.imshow('sobelxy', sobelxy)\n","    cv2.imshow('canny', canny)\n","    \n","    if cv2.waitKey(1) & 0xff == ord('q'):\n","        break\n","\n","cv2.destroyAllWindows()\n","cap.release()\n"],"metadata":{"id":"FJjPOpmuSNSx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **10) Template Matching**"],"metadata":{"id":"KwpFhhlRSPmK"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","#Load Larger Image\n","img_bgr = cv2.imread('full.jpg')\n","img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n","\n","#Load Template/Smaller image\n","template = cv2.imread('find.jpg', 0)\n","\n","w, h = template.shape[::-1]\n","\n","#Template Matching Process\n","res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)\n","threshold = 0.85\n","loc = np.where(res >= threshold)\n","\n","#Make rectangles at points templates are detected\n","for pt in zip(*loc[::-1]):\n","    cv2.rectangle(img_bgr, pt, (pt[0] + w, pt[1] + h), (0, 255, 255), 2)\n","\n","cv2.imshow('detected', img_bgr)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"],"metadata":{"id":"PMlpqkm9SYfz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **11) Grabcut Foreground Extraction**"],"metadata":{"id":"ZhKsMTxcTRn1"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","\n","# Load the image\n","img = cv2.imread('messi.jpg')\n","# Create a 0's mask\n","mask = np.zeros(img.shape[:2], np.uint8)\n","\n","# Create 2 arrays for background and foreground model\n","bgdModel = np.zeros((1, 65), np.float64)\n","fgdModel = np.zeros((1, 65), np.float64)\n","\n","rect = (500, 25, 300, 375)\n","mask, bgdModel, fgdModel = cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n","\n","mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n","img_seg = img * mask2[:, :, np.newaxis]\n","\n","cv2.imshow(\"img\", img_seg)\n","\n","\n","# Load the marked image\n","img_mark = cv2.imread('img1.png')\n","# Subtract to obtain the mask\n","mask_dif = cv2.subtract(img_mark, img_seg)\n","# Convert the mask to grey and threshold it\n","mask_grey = cv2.cvtColor(mask_dif, cv2.COLOR_BGR2GRAY)\n","ret, mask1 = cv2.threshold(mask_grey, 200, 255, 0)\n","\n","mask[mask1 == 255] = 1\n","mask, bgdModel, fgdModel = cv2.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n","\n","mask_final = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n","img_out = img * mask_final[:, :, np.newaxis]\n","\n","cv2.imshow('final', img_out)\n","cv2.waitKey(0)\n"],"metadata":{"id":"1eT6kVpnT5Pj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **12) Corner Detection**"],"metadata":{"id":"oCiz1m8nT-DA"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","#Load image \n","img = cv2.imread('corners.jpg')\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","gray = np.float32(gray)\n","\n","#Corner Detection Process\n","corners = cv2.goodFeaturesToTrack(gray, 20, 0.01, 10)\n","corners = np.int0(corners)\n","\n","#Making points at best 20 points detected\n","for corner in corners:\n","    x, y = corner.ravel()\n","    cv2.circle(img, (x, y), 3, 255, -1)\n","\n","cv2.imshow('corner', img)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"],"metadata":{"id":"Fg8EAlgzUGEB"},"execution_count":null,"outputs":[]}]}